
<!DOCTYPE html>
<html>
    <head>
        <title>Md Mostafijur Rahman's Homepage</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- UIkit CSS -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/css/uikit.min.css" />

        <!-- UIkit JS -->
        <script src="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/js/uikit.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/uikit@3.3.1/dist/js/uikit-icons.min.js"></script>

        <style>
            .uk-label{
                color: black;
                text-transform: none;
                background-color: transparent;
                border: 1px solid black;
                padding: 0px 3px;
            }
	    .news{
		    border: 1px solid black;
		    width: 98%;
		    height: 700px;
		    overflow-x: auto;
		    overflow-y: auto;
		    border-color: #e5e5e5;
		    padding: 10px;
		    background-color: #fff;
		    border-radius: 4mm;
	    }
	    .uk-text-bold {
		    font-weight: 600;
		}
	    .uk-h2, h2 {
		    font-size: 1.5rem;
		}
	    .uk-text-lead {
		    font-size: 1.0rem;
		    line-height: 1.5;
		    color: #333;
		}
	   .uk-text-lead {
		    font-size: 1.0rem;
		    line-height: 1.5;
		    color: #800000;
		}
        </style>
    </head>
    <body style="background-color: #FFFFFF">
        <nav class="uk-navbar-container uk-margin uk-light" style="background-color: #BF5701" uk-navbar>
            <div class="uk-navbar-left">
                <a class="uk-navbar-item uk-logo uk-text-primary" href="index.html">Md Mostafijur Rahman's Homepage</a>
            </div>
            <div class="uk-navbar-right">
                <ul class="uk-navbar-nav">
                    <li class="uk-active uk-visible@m"> <a href="index.html"> Home </a> </li>
		    <li class="uk-active uk-visible@m"> <a href="index.html#news"> Recent News </a> </li>
                    <li class="uk-active uk-visible@m"> <a href="index.html#research"> Research </a> </li>
		    <li class="uk-active uk-visible@m"> <a href="index.html#award"> Awards </a> </li>
                    <!--<li class="uk-active uk-visible@m"> <a href="resources.html"> Resources </a> </li>-->
                    <li class="uk-active uk-visible@m"> <a href="index.html#contact"> Contact </a> </li>
                    <!--<li class="uk-active uk-visible@m"> <a href="index.html#bio"> About </a> </li>-->
                    <a class="uk-active uk-navbar-toggle uk-hidden@m" uk-navbar-toggle-icon href="#offcanvas-nav-primary" uk-toggle></a>
                </ul>
            </div>
        </nav>

        <div id="offcanvas-nav-primary" uk-offcanvas="overlay: true">
            <div class="uk-offcanvas-bar uk-flex uk-flex-column">
                <ul class="uk-nav uk-nav-primary uk-nav-center uk-margin-auto-vertical">
                    <li class="uk-active"> <a href="index.html"> Home </a> </li>
		    <li class="uk-active"> <a href="index.html#news"> Recent News </a> </li>
                    <li class="uk-active"> <a href="index.html#research"> Research </a> </li>
		    <li class="uk-active"> <a href="index.html#award"> Awards </a> </li>
                    <!--<li class="uk-active"> <a href="resources.html"> Resources </a> </li>-->
                    <li class="uk-active"> <a href="index.html#contact"> Contact </a> </li>
                    <!--<li class="uk-active"> <a href="index.html#bio"> About </a> </li>-->
                </ul>
            </div>
        </div>

        <!-- Header -->
        <!-- <div class="uk-section uk-flex uk-flex-center uk-section-secondary uk-light"> -->
        <div class="uk-flex uk-flex-center">
            <div class="uk-container uk-width-1-1 uk-width-3-4@m uk-padding-small" uk-grid>
            <!-- <div class="uk-container uk-container-large uk-flex-middle uk-padding-small" uk-grid> -->
                <a class="uk-flex uk-flex-center uk-width-1-1 uk-width-auto@m" href="#">
                    <div class="uk-width-1-2 uk-width-medium@s uk-visible@l">
                        <img class="uk-border-circle uk-responsive-height uk-responsive-width" src="profile_pic_v2.jpg" alt="Portrait" /> </br>
		    </div>
		</a>

		<div class="uk-width-expand uk-margin-remove">
                    <p class="uk-h1 uk-text-center uk-text-left@m uk-width-expand@m uk-margin-remove">
                        Md Mostafijur Rahman
                    </p>
                    <p> <!--I am a member of 
			<b>System Level Design Group
			<a href = "https://radum.ece.utexas.edu/" style="color:#800000" target='_'>(SLD)</a> @UT Austin</b>.-->
                        I am a final year Ph.D. Candidate at 
			<a href = "https://www.ece.utexas.edu/" style="color:#800000" target='_'>
			The University of Texas at Austin</a> advised by <b><a href = "https://radum.ece.utexas.edu/people/" style="color:#800000" target='_'>Prof. Radu Marculescu</b>.</a> My research addresses <b>computational inefficiency</b>, <b>data scarcity</b>, <b>model robustness</b>, and <b>generalizability</b> in AI-driven biomedical imaging by <b>designing efficient and accurate architectures</b>, <b>multi-modal learning systems</b>, <b>generative techniques</b>, and <b>data-efficient robust training methods</b> for 2D/3D segmentation, synthesis, translation, denoising, and classification. By bridging the gap between AI advancements and clinical deployment, my work enables scalable, reliable solutions for real-world healthcare settings. My research accomplishments are evidenced by several impactful publications in top-tier venues, e.g., <b>CVPR</b> (2025, 2024), <b>MICCAI</b> (2025), <b>ICCV</b> (2025), <b>MIDL</b> (2025, 2023), <b>WACV</b> (2025, 2024, 2023), <b>ICASSAP</b> (2025), etc. Currently, I am working as an AI/ML PhD Intern at <a href = "https://www.gehealthcare.com/" style="color:#800000" target='_'>GE Healthcare</a>. In the past, I have interned at <a href = "https://www.nih.gov/" style="color:#800000" target='_'>National Institutes of Health (NIH)</a> and <a href = "https://www.bosch.us/our-company/innovation/" style="color:#800000" target='_'>Robert Bosch Research</a>.
                    </p>
		    <p>
			    Prior to joining <a href = "https://www.ece.utexas.edu/" style="color:#800000" target='_'>UT Austin</a>, I was a Graduate Student in Software Engineering at 
					<a href = "http://www.iitkgp.ac.in/" style="color:#800000" target='_'>University of Dhaka</a>. 
					I was advised by 
					<a href = "https://www.du.ac.bd/faculty/faculty_details/IIT/30" style="color:#800000" target='_'>Prof. Mohammad Shoyaib</a>. 
			    		I have also spent four wonderful years as a faculty (Assistant Professor and Lecturer) at <a href = "https://bu.ac.bd/?ref=teacher_profile_data_cse" style="color:#800000" target='_'>University of Barishal</a>. I had also an opportunity to work as a Senior Software Engineer at Advanced Solution Lab, <a href = "https://research.samsung.com/srbd" style="color:#800000" target='_'>Samsung Research, Bangladesh</a>.
	            </p>
		    <p>In my free time, I enjoy reading cutting-edge research across disciplines, experimenting with emerging algorithms, and traveling to new places ‚Äî pursuits that often broaden my perspective and fuel fresh ideas in my work.</p>
			
		    <p style="color:#fc2403"> <b> &#9827; I am currently on the job market, looking for tenure-track faculty or research roles. &#9827;</b></p>
                    <!-- Buttons for desktop device -->
                    <!--<div class="uk-margin-horizontal uk-visible@m">
                        <a href="#contact" class="uk-button uk-button-default uk-margin-small-right"> Mail </a>
                        <a href="https://scholar.google.com/citations?user=e0SzHPMAAAAJ" class="uk-button uk-button-default uk-margin-small-right" target='_'>Scholar </a>
                        <a href="https://github.com/mostafij-rahman" class="uk-button uk-button-default uk-margin-small-right" target='_'> GitHub </a>
                        <a href="https://www.linkedin.com/in/mostafij-rahman/" class="uk-button uk-button-default uk-margin-small-right" target='_'> LinkedIn </a>
			<a href="https://utexas.box.com/s/f93s0hfwhyxsbit74edl01ejw7o049of" class="uk-button uk-button-default uk-margin-small-right" target='_'> Resume/CV </a>
                    </div>-->
		    <div class="uk-margin-horizontal uk-flex uk-flex-center uk-visible@m">
                        <a href="#contact" class="uk-button uk-button-default uk-margin-small-right" uk-icon="mail"></a>
                        <a href="https://scholar.google.com/citations?user=e0SzHPMAAAAJ" class="uk-button uk-button-default uk-margin-small-right" uk-icon="google" target='_'></a>
                        <a href="https://github.com/mostafij-rahman" class="uk-button uk-button-default uk-margin-small-right" uk-icon="github" target='_'></a>
                        <a href="https://www.linkedin.com/in/mostafij-rahman/" class="uk-button uk-button-default uk-margin-small-right" uk-icon="linkedin" target='_'></a>
                    	<a href="https://utexas.box.com/s/f93s0hfwhyxsbit74edl01ejw7o049of" class="uk-button uk-button-default uk-margin-small-right" target='_'> Resume/CV </a>
                    </div>
                    <!-- Buttons for mobile device -->
                    <div class="uk-margin-horizontal uk-flex uk-flex-center uk-hidden@m">
                        <a href="#contact" class="uk-button uk-button-default uk-margin-small-right" uk-icon="mail"></a>
                        <a href="https://scholar.google.com/citations?user=e0SzHPMAAAAJ" class="uk-button uk-button-default uk-margin-small-right" uk-icon="google" target='_'></a>
                        <a href="https://github.com/mostafij-rahman" class="uk-button uk-button-default uk-margin-small-right" uk-icon="github" target='_'></a>
                        <a href="https://www.linkedin.com/in/mostafij-rahman/" class="uk-button uk-button-default uk-margin-small-right" uk-icon="linkedin" target='_'></a>
                    </div>
                </div>
            </div>
        </div>

        <!-- Body -->
        <div class="uk-flex uk-flex-center uk-margin-remove-top uk-margin-medium-bottom">
        <div class="uk-container uk-width-1-1 uk-width-3-4@m uk-padding-small">

            <p id="news" class="uk-h2 uk-text-bold">Recent News</p>
            <ul class="uk-list uk-list-bullet uk-margin-small-bottom news">
		<li><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <b>July 2025:</b> 1 paper introducing ultra-lightweight 2D CNN-based segmentation architecture (<a href = "#" style="color:#800000" target='_'>MK-UNet</a>) accepted to <b>ICCVW 2025</b> as an Oral.</li>
		<li><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <b>July 2025:</b> Attended <b>MIDL 2025</b> and delivered an <b>Oral talk</b> on our paper, <a href = "https://openreview.net/pdf?id=VQX4B2A2Y0" style="color:#800000" target='_'>PRIME</a>, on data efficient AI</li>
		<li><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <b>July 2025:</b> Received the üèÖ <b>MIDL 2025 Travel Award</b> to attend and present <a href = "https://openreview.net/pdf?id=VQX4B2A2Y0" style="color:#800000" target='_'>PRIME</a> in Salt Lake City.</li>
		<li><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <b>July 2025:</b> Received the üèÖ <b>MICCAI 2025 NIH Registration Grant</b> to attend and present <a href = "#" style="color:#800000" target='_'>EfficientMedNeXt</a> in Daejeon, with support for main conference and satellite registrations, plus MICCAI Society membership.</li>
		<li><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <b>June 2025:</b> 1 paper introducing lightweight 3D segmentation architecture (<a href = "#" style="color:#800000" target='_'>EfficientMedNeXt</a>) accepted to <b>MICCAI 2025</b>.</li>
		<li><b>June 2025:</b> Attended <b>CVPR 2025</b> and presented our two papers (<a href = "https://openaccess.thecvf.com/content/CVPR2025/html/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.html" style="color:#800000" target='_'>EffiDec3D</a> and <a href = "https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Munir_From_Data_to_Design_Leveraging_Frequency_Statistics_for_Efficient_Neural_CVPRW_2025_paper.html" style="color:#800000" target='_'>From Data to Design</a>).</li>
		<li><b>June 2025:</b> Attended <b>Stanford AI Week 2025</b> with an in-person attendance <b>scholarship</b> (AIMI, RAISE, and Pediatric AIMI Symposiums).</li>
		<li><b>May 2025:</b> Selected to participate in the <b>MIDL 2025 Doctoral Symposium</b> in Salt Lake City.</li>
		<li><b>May 2025:</b> I have joined <b>GE Healthcare</b>, San Ramon as a 2025 <b>AI/ML PhD Intern</b>.</li> 
		<li><b>April 2025:</b> Received the üèÖ <b>CVPR 2025 Broadening Participation Award</b> to attend and present our recent work, <a href = "https://openaccess.thecvf.com/content/CVPR2025/html/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.html" style="color:#800000" target='_'>EffiDec3D</a>, at CVPR in Nashville.</li>
		<li><b>April 2025:</b> Invited Talk on "Towards Efficient AI for Biomedical Imaging: Reducing Computation and Data Demands" at <a href = "https://stanford-medai.github.io/" style="color:#800000" target='_'><b>Stanford MedAI</b></a>.  <a href = "https://www.youtube.com/watch?v=HsqIxvm8Sdw" style="color:#800000" target='_'>Watch Recording</a>.</li>
		<li><b>April 2025:</b> Our efficient 3D segmentation paper (<a href = "https://openaccess.thecvf.com/content/CVPR2025/html/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.html" style="color:#800000" target='_'>EffiDec3D</a>) received the üèÖ <b>Highlight award at CVPR 2025 (top 2.98% of submissions)</b>.</li>
		<li><b>March 2025:</b> 1 paper introducing data-driven architecture (<a href = "https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Munir_From_Data_to_Design_Leveraging_Frequency_Statistics_for_Efficient_Neural_CVPRW_2025_paper.html" style="color:#800000" target='_'>From Data to Design</a>) accepted to <b>CVPRW 2025</b> on Efficient Large Vision Models.</li>
		<li><b>March 2025:</b> 1 paper addressing data inefficiency by applying community detection in image similarity network (<a href = "https://openreview.net/pdf?id=VQX4B2A2Y0" style="color:#800000" target='_'>PRIME</a>) accepted to <b>MIDL 2025</b>.</li>
		<li><b>February 2025:</b> 1 paper addressing complutational complexity of 3D segmentation (<a href = "#" style="color:#800000" target='_'>EffiDec3D</a>) accepted to <b>CVPR 2025</b>.</li>
		<li><b>February 2025:</b> Attended <b>UT System Trauma Research Symposium</b> 2025. </li>
		<li><b>January 2025:</b> Presented a poster at <b>GAIN 2025</b> on "Efficient Multi-scale Convolutional Attention Decoding for Medical Image Segmentation". </li>
		<li><b>December 2024:</b> 1 paper addressing robustness in 2D medical image segmentation (<a href = "https://arxiv.org/abs/2405.06166" style="color:#800000" target='_'>MDNet</a>) accepted to <b>ICASSP 2025</b>.</li>
		<li><b>October 2024:</b> Our collaborative research with Dell Med on Biomedical imaging <b>featured in <a href = "https://news.utexas.edu/2024/10/17/ai-in-the-gi/" style="color:#800000" target='_'>UT News</b></a>.</li>
		<li><b>October 2024:</b> 1 paper introducing computationally efficient vision model (<a href = "https://arxiv.org/abs/2412.10995" style="color:#800000" target='_'>RapidNet</a>) accepted to <b>WACV 2025</b>.</li>
		<li><b>September 2024:</b> 1 abstract (Few-shot Image Denoising) accepted to <b>EPFL Latsis Symposium on Smart Microscopy 2024</b> from internship at NIH.</li>
		<li><b>August 2024:</b> Invited Talk: Gave a talk at NHLBI, NIH on "Efiicient Deep Learning for Biomedical Imaging". </li>
		<li><b>August 2024:</b> Presented a poster at NIH on "Universal Light Microscopy Denoising via Lightweight Multi-scale Convolutional Transformer".</li>
		<li><b>July 2024:</b> Won üèÖ The <b>Texas Health Catalyst Award 2024</b> for our "Medical Image Segmentation via Cascaded Attention Decoding".</li>
		<li><b>May 2024:</b> I have joined Office of AI Research (OAIR), NHLBI, NIH as 2024 <b>Summer IRTA Fellow</b> to work with Sarah Hopper and Christian Combs.</li> 
		<li><b>April 2024:</b> 1 paper addressing the robustness of finetuning vision foundation model for polyp segmentation (<a href = "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Rahman_PP-SAM_Perturbed_Prompts_for_Robust_Adaption_of_Segment_Anything_Model_CVPRW_2024_paper.html" style="color:#800000">PP-SAM</a> || <a href = "https://github.com/SLDGroup/PP-SAM" style="color:#800000">[Code]</a>) accepted to <b>CVPRW 2024</b> on Domain adaptation Explainability and Fairness in AI for Medical Image Analysis.</li>
		<li><b>March 2024:</b> Received the prestigious üèÖ <b>Summer IRTA Fellowship</b> from Office of AI Research (OAIR), NHLBI, NIH to work with Sarah Hopper, Christian Combs, and Hui Xue.</li> 
		<li><b>February 2024:</b> 2 papers introducing efficient multi-scale convolutional attention-based decoder for 2D medical image segmentation (<a href = "https://openaccess.thecvf.com/content/CVPR2024/html/Rahman_EMCAD_Efficient_Multi-scale_Convolutional_Attention_Decoding_for_Medical_Image_Segmentation_CVPR_2024_paper.html" style="color:#800000">EMCAD</a> || <a href = "https://github.com/SLDGroup/EMCAD" style="color:#800000">[Code]</a>) and dynamic graph construction-based vision backbone (<a href = "https://openaccess.thecvf.com/content/CVPR2024/html/Munir_GreedyViG_Dynamic_Axial_Graph_Construction_for_Efficient_Vision_GNNs_CVPR_2024_paper.html" style="color:#800000">GreedyViG</a> || <a href = "https://github.com/SLDGroup/GreedyViG" style="color:#800000">[Code]</a>) accepted to <b>CVPR 2024</b>.</li>
		<li><b>January 2024:</b> Presented a poster at <b>GAIN 2024</b> on "Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation". </li>
		<li><b>August 2023:</b> 1 paper introducing a graph convolution-based decoder for 2D medical image segmentation (<a href = "https://openaccess.thecvf.com/content/WACV2024/html/Rahman_G-CASCADE_Efficient_Cascaded_Graph_Convolutional_Decoding_for_2D_Medical_Image_WACV_2024_paper.html" style="color:#800000">G-CASCADE</a>) accepted to <b>WACV 2024</b>.</li>
		<li><b>July 2023:</b> Received üèÖ <b>Professional Development Award</b> by the Graduate School, UT Austin</li>
		<li><b>May 2023:</b> Spending Summer 2023 in <b>Robert Bosch Research</b>, Pittsburgh as Machine Learning Reseach Intern.</li>
		<li><b>April 2023:</b> Won the üèÖ <b>Ram‚Äôs Horn Best Project Award</b> in Digital Video course by <b>Prof. Alan Bovik</b>, UT Austin.</li>
		<li><b>March 2023:</b> Received the üèÖ <b>Best Poster Award</b> (for CASCADE) by Graduate and Industry Networking (<b>GAIN 2023</b>), UT Austin.</li>
		<li><b>March 2023:</b> Presented a poster at <b>GAIN 2023</b> on "Medical Image Segmentation via Cascaded Attention Decoding". </li>
		<li><b>March 2023:</b> 1 paper introducing a multi-scale hierarchical network and combinatorial supervision (<a href = "https://proceedings.mlr.press/v227/rahman24a.html" style="color:#800000">MERIT</a>) accepted to <b>MIDL 2023</b>.</li>
		<li><b>October 2022:</b> 1 paper introducing the first convolutational attention-based decoding (<a href = "https://openaccess.thecvf.com/content/WACV2023/html/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.html" style="color:#800000">CASCADE</a>) accepted to <b>WACV 2023</b>.</li>
            	<li><b>May 2022:</b> Received the üèÖ <b>Feldman Graduate Research Fellowship</b>, The University of Texas at Austin.</li>
		<li><b>January 2022:</b> I have started the Doctor of Philospohy in Electrical and Computer Engineering, The University of Texas at Austin (UT Austin). I have joined the System Level Design Group (SLD) advised by Prof. Radu Marculescu.</li>
	    </ul>

            <p id="research" class="uk-h2 uk-text-bold">Selected Publication
		    [<b><a href = "https://scholar.google.com/citations?user=e0SzHPMAAAAJ" style="color:#FF4422;">Full List</a></b>]</p>
            <ul class="uk-list uk-margin-small-bottom">
		<!--<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[XXXXXX 2025]</b></span> &nbsp;  PipeFlow: Pipelining Inversion and Editing for Faster Long Form Video Synthesis.</div>
                    <div> Mustafa Munir, <b>Md Mostafijur Rahman</b>, Kartikeya Bhardwaj, Radu Marculescu. </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>-->
		
		<li>
                    <div class="uk-text-lead"><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <span style="color:#b30749"><b>[ICCVW 2025]</b></span> &nbsp;  MK-UNet: Multi-kernel Lightweight CNN for Medical Image Segmentation.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Radu Marculescu.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
		    <span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Accepted</span>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <span style="color:#b30749"><b>[MICCAI 2025]</b></span> &nbsp; EfficientMedNeXt: Multi-Receptive Dilated Convolutions for Medical Image Segmentation.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Mustafa Munir, Radu Marculescu. </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
		    <span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Accepted</span>
                </li>
		
		<li>
                    <div class="uk-text-lead"><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <span style="color:#b30749"><b>[CVPR 2025]</b></span> &nbsp; EffiDec3D: An Optimized Decoder for Efficient High-Performance 3D Medical Image Segmentation.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Radu Marculescu. </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.html" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/SLDGroup/EffiDec3D" target="_blank" class="uk-button uk-button-text">[Code]</a>
		    <span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Highlight üèÖ</span>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <span style="color:#b30749"><b>[CVPRW 2025]</b></span> &nbsp;  From Data to Design: Leveraging Frequency Statistics for Efficient Neural Network Architectures.</div>
                    <div> Mustafa Munir, Guihong Li, <b>Md Mostafijur Rahman</b>, Radu Marculescu. </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Munir_From_Data_to_Design_Leveraging_Frequency_Statistics_for_Efficient_Neural_CVPRW_2025_paper.html" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
		
		<li>
                    <div class="uk-text-lead"><span style="color:#e60000; font-weight:bold;">New</span>&nbsp; <span style="color:#b30749"><b>[MIDL 2025]</b></span> &nbsp;  Training-Free Dataset Pruning for Polyp Segmentation via Community Detection in Similarity Networks.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Radu Marculescu. </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://openreview.net/pdf?id=VQX4B2A2Y0" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
			<span style="background-color: lightgreen; padding: 2px 5px; border-radius: 5px;">Oral</span>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[ICASSP 2025]</b></span> &nbsp;  MDNet: Multi-Decoder Network for Abdominal CT Organs Segmentation.</div>
                    <div> Debesh Jha, Nikhil Kumar Tomar, Koushik Biswas, Gorkem Durak, Matthew Antalek, Zheyuan Zhang, Bin Wang, <b>Md Mostafijur Rahman</b>, Hongyi Pan, Alpay Medetalibeyoglu, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://arxiv.org/abs/2405.06166" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[WACV 2025]</b></span> &nbsp;  RapidNet: Multi-Level Dilated Convolution Based Mobile Backbone.</div>
                    <div> Mustafa Munir, <b>Md Mostafijur Rahman</b>, and Radu Marculescu. <b style="color:#FF4422;">[üèÖ *GAIN Best Poster Award 2025 Winner]</b> </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://arxiv.org/abs/2412.10995" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[CVPR 2024]</b></span> &nbsp;  EMCAD: Efficient Multi-scale Convolutional Attention Decoding for Medical Image Segmentation.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Mustafa Munir, and Radu Marculecu.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://cvpr.thecvf.com/virtual/2024/poster/30814" target="_blank" class="uk-button uk-button-text">[Paper]</a>
		    <a href="https://arxiv.org/abs/2405.06880" target="_blank" class="uk-button uk-button-text">[arxiv]</a>
                    <a href="https://github.com/SLDGroup/EMCAD" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[CVPR 2024]</b></span> &nbsp;  GreedyViG: Dynamic Axial Graph Construction for Efficient Vision GNNs.</div>
                    <div> Mustafa Munir, William Avery, <b>Md Mostafijur Rahman</b>, and Radu Marculecu.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://cvpr.thecvf.com/virtual/2024/poster/30880" target="_blank" class="uk-button uk-button-text">[Paper]</a>
	            <a href="https://arxiv.org/abs/2405.06849" target="_blank" class="uk-button uk-button-text">[arxiv]</a>
                    <a href="https://github.com/SLDGroup/GreedyViG" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[CVPRW 2024]</b></span> &nbsp;  PP-SAM: Perturbed Prompts for Robust Adaptation of Segment Anything Model for Polyp Segmentation.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Mustafa Munir, Debesh Jha, Ulas Bagci, and Radu Marculescu.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Rahman_PP-SAM_Perturbed_Prompts_for_Robust_Adaption_of_Segment_Anything_Model_CVPRW_2024_paper.pdf" target="_blank" class="uk-button uk-button-text">[Paper]</a>
		    <a href="https://arxiv.org/abs/2405.16740" target="_blank" class="uk-button uk-button-text">[arxiv]</a>
                    <a href="https://github.com/SLDGroup/PP-SAM" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[WACV 2024]</b></span> &nbsp;  G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation.</div>
                    <div>  <b>Md Mostafijur Rahman</b>, Radu Marculescu.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://openaccess.thecvf.com/content/WACV2024/html/Rahman_G-CASCADE_Efficient_Cascaded_Graph_Convolutional_Decoding_for_2D_Medical_Image_WACV_2024_paper.html" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://arxiv.org/abs/2310.16175" target="_blank" class="uk-button uk-button-text">[arxiv]</a>
		    <a href="https://github.com/SLDGroup/G-CASCADE" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[MIDL 2023]</b></span> &nbsp; Multi-scale Hierarchical Vision Transformer with Cascaded Attention Decoding for Medical Image Segmentation.</div>
                    <div>  <b>Md Mostafijur Rahman</b>, Radu Marculescu.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="https://proceedings.mlr.press/v227/rahman24a/rahman24a.pdf" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://arxiv.org/abs/2303.16892" target="_blank" class="uk-button uk-button-text">[arxiv]</a>
                    <a href="https://github.com/SLDGroup/MERIT" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[WACV 2023]</b></span> &nbsp;  Medical Image Segmentation via Cascaded Attention Decoding.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Radu Marculescu.  <b style="color:#FF4422;">[ üèÖ *GAIN Best Poster Award 2023 Winner, **The Texas Health Catalyst Award 2024 Winner, ***UT Proof of Concepts Award Winner]</b></div>
                    <div class="uk-text-lead"></div>
		    <a href="https://openaccess.thecvf.com/content/WACV2023/html/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.html" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="https://github.com/SLDGroup/CASCADE" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>

		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[SIGSPATIAL GeoAI 2021]</b></span> &nbsp;  Mapping Road Safety Barriers Across Street View Image Sequences: A Hybrid Object Detection and Recurrent Model.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Arpan Man Sainju, and Zhe Jiang.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[ICIEV 2019]</b></span> &nbsp;  Bangla Handwritten Basic Character Recognition Using Deep Convolutional Neural Network.</div>
                    <div> Chandrika Saha, Rahat Hossain Faisal, and <b>Md Mostafijur Rahman</b>.  </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[J-SIVP 2018]</b></span> &nbsp;  MCCT: a Multi-channel Complementary Census Transform for Image Classification.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Shanto Rahman, and Mohammad Shoyaib. </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[JIVP 2017]</b></span> &nbsp; DTCTH: a Discriminative Local Pattern Descriptor for Image Classification.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Shanto Rahman, Rayhanur Rahman, Mainul Hossain, and Mohammad Shoyaib. </div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[JIVP 2016]</b></span> &nbsp; An Adaptive Gamma Correction for Image Enhancement.</div>
                    <div> Shanto Rahman, <b>Md Mostafijur Rahman</b>, M. Abdullah-Al-Wadud, Golam Dastegir Al-Quaderi, and Mohammad Shoyaib. <b style="color:#FF4422;">[*Used by NIH in MIPAV API]</b></div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
		<li>
                    <div class="uk-text-lead"><span style="color:#b30749"><b>[ICCIT 2015]</b></span> &nbsp;  Noise Adaptive Binary Pattern for Face Image Analysis.</div>
                    <div> <b>Md Mostafijur Rahman</b>, Shanto Rahman, Minhas Kamal, M. Abdullah-Al-Wadud, Emon Kumar Dey, and Mohammad Shoyaib.  <b style="color:#FF4422;">[üèÖ *Best Paper Award]</b></div>
                    <div class="uk-text-lead"></div>
		    <a href="#" target="_blank" class="uk-button uk-button-text">[Paper]</a>
                    <a href="#" target="_blank" class="uk-button uk-button-text">[Code]</a>
                </li>
            </ul>

	    <p id="award" class="uk-h2 uk-text-bold">Awards</p>
            <ul class="uk-list uk-list-bullet">
		<li>MIDL 2025 Travel Award, MIDL - July 2025</li>
		<li>MICCAI 2025 NIH Registration Grant, MICCAI - July 2025</li>
		<li>CVPR 2025 Broadening Participation Award, CVPR - June 2025</li>
		<li>Stanford AIMI In-person Attendance Scholarship, Stanford AIMI25 - June 2025</li>
		<li>The Texas Health Catalyst Award, The University of Texas at Austin - 2024</li>
		<li>Summer IRTA Fellowship, Office of AI Research (OAIR), National Institutes of Health (NIH) - Summer 2024</li> 
		<li>Professional Development Award, Graduate School, The University of Texas at Austin - July 2023</li>
		<li>Ram‚Äôs Horn Best Project Award, The University of Texas at Austin - May 2023</li>
		<li>Best Poster Award, Graduate and Industry Networking (GAIN), The University of Texas at Austin - March 2023</li>
		<li>Feldman Graduate Research Fellowship, The University of Texas at Austin - Summer 2022</li>
		<li>Graduate Council Research Fellowship, The University of Alabama, Tuscaloosa - 2021</li>
		<li>Innovation Award, Innovation Lab, Access to Information (A2I), Prime Minister‚Äôs Office, Bangladesh - 2018</li>
		<li>Research Grant, University Grants Commission (UGC), Bangladesh, for Medical Image Enhancement project - 2017-2018</li>
		<li>Graduate Merit Award (top 1%), University of Dhaka, Bangladesh - 2016</li>
		<li>Best Paper Award (1st Prize), 18th Int. Conference on Computer and Information Technology (ICCIT) - December 2015</li>
		<li>Research Fellowship, M.Sc., Ministry of Information and Communication Technology, Bangladesh - 2015-2016</li>
		<li>Undergraduate Merit Award (top 1%), University of Dhaka, Bangladesh - 2015</li>
		<li>Merit Scholarship (top 1%), Fazlul Haque Muslim Hall, University of Dhaka - 2014</li>
		<li>Undergraduate Merit Scholarship, Board of Intermediate and Secondary Education, Bangladesh - 2011-2014</li>
	    </ul>
		
            <p class="uk-h2 uk-text-bold">Teaching & Service</p>
            <ul class="uk-list uk-list-bullet">
		<li>
                    Teaching Assistant: EE319K Introduction to Embedded Systems course by Prof. Jonathan Valvano [UT Austin]
		</li>
                <li>
                    Conference Reviewer: ICCV 2025, MICCAI 2025, CVPR 2025, ICLR 2025, NeurIPS 2024, MICCAI 2024, WACV 2024-2025, ISBI 2024-2025.
		</li>
		<li>
                    Journal Reviewer: PAMI, TMI, TIP, Pattern Recognition Letters, PLOS ONE.
		</li>

            </ul>

            <p id="contact" class="uk-h2 uk-text-bold">Contact</p>
            <div class="uk-child-width-1-2@m" uk-grid>
                <div class="uk-width-large">
                    <div class="uk-card uk-card-default uk-card-hover uk-card-body">
                        <h3 class="uk-card-title">Address</h3>
                        <p>
                            EER 5.838B <br/>
                            2501 Speedway <br/>
                            Austin, TX  <br/>
                            United States <br/>
                            78712
                        </p>
                    </div>
                </div>
                <div class="uk-width-large">
                    <div class="uk-card uk-card-primary uk-card-hover uk-card-body"  style="background-color: #BF5701">
                        <h3 class="uk-card-title">Email</h3>
                        <p>
                            <b>Academic</b> <br/>
                            mostafijur.rahman [at] utexas.edu
                            <br/><br/>
                            <b>Other Use</b> <br/>
                            mostafij.csebu [at] gmail.com
                        </p>
                    </div>
                </div>
            </div>

            <!--<p id="bio", class="uk-h2 uk-text-bold">About Me</p>
            <article class="uk-article">
		Born is a small town (Belthara) in Eastern UP, India, I got my hands on a computer first time during my undergraduate freshman year. 
		My journey in computer science began when I was sixteen year old with a fantastic book "Let Us C" by Yashavant Kanetkar. During my career, I have 
		always tried to make best use of resources and smart people around me to learn and grow. I identified my research potential while working with Prof. Animesh 
		Mukherjee in IIT Kharagpur and later spent some wonderful time in Samsung Research after graduating. Currently, with the grace of GOD, I am very previlaged
		to work and supervised by some extremely brilliant minds in <a href = "https://vita-group.github.io/" style="color:#800000">VITA</a> 
		and  <a href = "https://aihealth.ischool.utexas.edu/" style="color:#800000">AI Health </a> @ UT Austin.
                <blockquote cite="#">
                    <p class="uk-margin-small-bottom">Somewhere, something incredible is waiting to be known.</p>
                    <footer><cite>Prof. Carl Sagan</cite></footer>
                </blockquote>
		<a href="https://www.easycounter.com/">
			<img src="https://www.easycounter.com/counter.php?ajayjaiswal23"
			border="0" alt="Free Hit Counters"></a>
			<br><a href="https://www.easycounter.com/">Visitor Counter</a>
            </article>-->
        </div>
        </div>


        

        <!-- Footer -->
        <div class="uk-section uk-flex uk-flex-center uk-section-secondary uk-height-small" style="background-color: #BF5701">
            <div class="uk-container uk-container-large uk-text-primary">
                <p class="uk-text-small uk-text-center">Copyright &copy; 2024 Md Mostafijur Rahman. All Rights Reserved.</p>
                <!--<p class="uk-text-small uk-text-center">Powered by <span uk-icon="uikit">UIkit</span></p>-->
            </div>
        </div>

    </body>
</html>


<!-- 		<div class="blurb" style="font-family: Arial, Helvetica, sans-serif;">
			<div style="width:750px; height:400px;  float:right; margin-top:20px;">
				<p style="font-size:20px;display: inline-block;">I am a Ph.D. student at the 
					<a href = "https://www.ischool.utexas.edu/" style="color:#800000">
					School of Information, UT Austin</a>. I am fortunate to be advised by 
					<b><a href = "https://yingding.ischool.utexas.edu/" style="color:#800000">Prof. Ying Ding</a></b>, and 
					<b><a href = "https://www.ece.utexas.edu/people/faculty/atlas-wang" style="color:#800000">Prof. Atlas Wang</b>.</a> I am a member of 
					<b>Visual Informatics Group
					<a href = "https://vita-group.github.io/" style="color:#800000">(VITA)</a> @UT Austin</b>. 
					My primary research revolves around Multi-Modal Systems, Model Interpretability and Optimization. I am currently working on 
					designing and improving explainability of the
					training recipe for Sparse Neural Networks. I am also developing AI algorithms 
					across computer vision, natural language processing which assists in critical medical decision-making.</p>

				<p style="font-size:20px;display: inline-block;">Prior to joining UT Austin, I completed my Masters in Computer Science from 
					<a href = "http://www.iitkgp.ac.in/" style="color:#800000">Indian Institute of Technology, Kharagpur</a>. 
					I was advised by 
					<a href = "https://cse.iitkgp.ac.in/~animeshm/" style="color:#800000">Prof. Animesh Mukherjee</a> and 
					<a href = "https://cse.iitkgp.ac.in/~pawang/" style="color:#800000">Prof. Pawan Goyal</a> at the CNeRG Lab. I have also worked as Lead Research Engineer 
					at Advanced Technology Lab, Samsung Electronics, India under the supervision of
					<a href="https://scholar.google.com/citations?hl=en&user=E6Gasu0AAAAJ&view_op=list_works&sortby=pubdate" style="color:#800000">Dr. Vijay Narayan Tiwari</a>.</p>
				<p style="font-size:20px;display: inline-block; color:red"><i>Somewhere, something incredible is waiting to be known.</i> ~Prof. Carl Sagan</p>
			</div>
			<img src="/picturedp.PNG" alt="Italian Trulli" style="width:200px;height:200px;">
			<h3>Md Mostafijur Rahman</h3>
			<p>PhD Student - UT Austin</p>
			<p>School of Information</p>
			<p style="font-size:12px">Office: UTA 5.410, 1616 Guadalupe St</p>
			<ul>
				   <li><a href="mailto:ajayjaiswal@utexas.edu">Email</a></li>
				   <li><a href="https://scholar.google.com/citations?user=I783HxYAAAAJ&hl=en">Google Scholar</a></li>
			</ul>
		</div> 
		<h2 style = "font-size:20px">News Updates</h2>
		<hr/>
		<div style ="font-size:14px; font-family: Arial, Helvetica, sans-serif;">
			<strong>May, 2022</strong> &emsp;Our work - 'Training Your Sparse Neural Network Better with Any Mask' got accpeted at <a href = "https://icml.cc/Conferences/2022/CallForPapers" style="color:#800000">ICML 2022</a>.</br>
			<strong>Feb, 2022</strong> &emsp; Awarded Professoional Development Award by School of Information, UT Austin </br> 
			<strong>Aug, 2021</strong> &emsp;Our work - 'SCALP - Supervised Contrastive Learning for Cardiopulmonary Disease Classification and Localization in Chest X-rays using Patient Metadata' got accpeted at <a href = "https://icdm2021.auckland.ac.nz/" style="color:#800000">ICDM 2021</a>.</br>
			<strong>JuL, 2021</strong> &emsp;Winner of the <a href = "https://aihealth.ischool.utexas.edu/AIHealthChallenge/index.html" style="color:#800000">AI Health Data Challenge</a> at UT Austin. (First Prize - $1000)</br>
			<strong>Jun, 2021</strong> &emsp;Our work - 'Using Radiomics as Prior Knowledge for Thorax Disease Classification and Localization in Chest X-rays' got accpeted at AMIA 2021.</br>
			<strong>Jun, 2021</strong> &emsp;Started Working as Graduate Research Assistant with <a href = "http://www.katrinerk.com/" style="color:#800000"> Prof. Katrin Erk </a> on Narrative Inference. </br>
			<strong>Mar, 2021</strong> &emsp;Presented our paper "Understanding Parachuting Collaboration" at iConference 2021.</br>
			<strong>Jan, 2021</strong> &emsp;Started PhD in Information Science at University of Texas at Austin</br>
			<strong>Jan, 2021</strong> &emsp;Receipent of Kilgarlin Fellowship ($2,500/semester - 2021 to 2024)</br>
			<strong>Jan, 2021</strong> &emsp;Receipent of William and Margaret Kilgarlin Endowed Scholarship ($54,750 - 2021 to 2022)</br>
			<strong>Dec, 2020</strong> &emsp;Left job at Advanced Technology Lab, Samsung Electronics, Banglore, India.</br>
			<strong>Feb, 2020</strong> &emsp;Our submitted systems ranked 2nd, and 3rd place for Task 4, and 11 at 
						<a href = "https://alt.qcri.org/semeval2020/index.php?id=tasks" style="color:#800000">SemEval 2020</a>.</br>
		</div>
		<h2 style = "font-size:16px">Select Publications (*Equal Contribution)</h2>
		<hr/>
		<div style ="font-size:14px; font-family: Arial, Helvetica, sans-serif;">
			<p><strong>Training Your Sparse Neural Network Better with Any Mask</strong><br/>
			<u>Md Mostafijur Rahman</u>, Haoyu Ma, Tianlong Chen, Ying Ding, Ying Ding, Atlas Wang<br/>
		        International Conference on Machine Learning (ICML), 2022. 
			</p>
			<p><strong>RadBERT-CL: Factually-Aware Contrastive Learning ForRadiology Report Classification</strong><br/>
			<u>Md Mostafijur Rahman</u>, Liyan Tang, Meheli Ghosh, Justin Rousseau, Yifan Peng, and Ying Ding<br/>
		        2021 Machine Learning for Health (ML4H 2021)
			</p>
			<p><strong>Using Radiomics as Prior Knowledge for Abnormality Classification and Localization in Chest X-rays</strong><br/>
			Yan Han, Chongyan Chen, Liyan Tang, Mingquan Lin, <u>Md Mostafijur Rahman</u>, Ying Ding, Yifan Peng<br/>
		        2021 American Medical Informatics Association Annual Symposium 
			</p>
			<p><strong>Understanding Parachuting Collaboration</strong><br/>
			<u>Md Mostafijur Rahman</u>, Meijun Liu, Ying Ding<br/>
		        2021 Diversity, Divergence, Dialogue: 16th International Conference, iConference 
			</p>
			<p><strong>Ensemble Architecture for Fine-Tuned Propaganda Detection in News Articles</strong><br/>
			Mayank Raj*, <u>Md Mostafijur Rahman</u>*, RR Rohit, Ankita Gupta, Sudeep Kumar Sahoo, Vertika Srivastava, Yeon Hyang Kim<br/>
			2020 Proceedings of the Fourteenth Workshop on Semantic Evaluation, 1802-1807
			</p>
			<p><strong>Be Reasonable: Exploiting Large-scale Language Models for Commonsense Reasoning</strong><br/>
			Vertika Srivastava, Sudeep Kumar Sahoo, Yeon Hyang Kim, Rohit Rr, Mayank Raj, <u>Md Mostafijur Rahman</u><br/>
			2020 Proceedings of the Fourteenth Workshop on Semantic Evaluation, 585-593
			</p>
			<p><strong>Understanding the impact of early citers on long-term scientific impact</strong><br/>
			Mayank Singh, <u>Md Mostafijur Rahman</u>, Priya Shree, Arindam Pal, Animesh Mukherjee, Pawan Goyal<br/>
			2017 ACM/IEEE Joint Conference on Digital Libraries (JCDL)
			</p>
		</div>
 -->

